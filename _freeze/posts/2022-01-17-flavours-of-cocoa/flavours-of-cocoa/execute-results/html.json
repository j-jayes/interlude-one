{
  "hash": "64e6934f61613627c672b3e1e7af8be2",
  "result": {
    "markdown": "---\ntitle: \"Flavours of cocoa\"\ndescription: |\n  An exploration of chocolate bar reviews\nauthor:\n  - name: Jonathan Jayes\n    url: {interludeone.com}\ndate: 2022-02-15\nimage: images/preview.png\noutput:\n  distill::distill_article:\n    self_contained: false\n    code_folding: false\n    highlight: haddock\n    highlight_downlit: true\n    toc: true\n---\n\n\n\n\n# Flavours of Cocoa\n\nWelcome to the first in a series of data screencasts where I attempt to show you how great the R language is.\n\nThis post follows along with the data screencast and includes the code methodically.\n\nIt begins by reading in the data, then tidying it up, analysing it, making some visualizations and then performing some predictive modelling.\n\n## Beans?\n\nI'm signed up to a fantastic newsletter called [\"Data is Plural\"](https://www.data-is-plural.com/) curated by journalist Jeremy Singer-Vine. Truly, it is a treasure trove of interesting public datasets from all over the internet. You can sign up to the newsletter [here](https://buttondown.email/data-is-plural) if this sounds up your alley. \n\nThis week it included a link to a fun selection of chocolate bar reviews, which Jeremy described as:\n\n<blockquote>\n\nChocolate bar reviews. The [Manhattan Chocolate Society](http://flavorsofcacao.com/mcs_index.html)’s [Brady Brelinski](http://flavorsofcacao.com/contact.html) has reviewed 2,500+ bars of craft chocolate since 2006, and compiles his findings into a [copy-paste-able](http://flavorsofcacao.com/chocolate_database.html) table that lists each bar’s manufacturer, bean origin, percent cocoa, ingredients, review notes, and numerical rating.\n\n</blockquote>\n\nA live link to the database is shown below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::include_url(\"http://flavorsofcacao.com/chocolate_database.html\")\n```\n\n<iframe src=\"http://flavorsofcacao.com/chocolate_database.html\" width=\"672\" height=\"400px\" data-external=\"1\"></iframe>\n:::\n\n\n## Ingest the data\n\nI've copied and pasted the data into an Excel spreadsheet, accessible on my [Github](https://github.com/j-jayes/jjayes_distill/blob/main/posts/2022-01-17-flavours-of-cocoa/data/chocolate-bar-ratings.xlsx) if you want to download it an analyse it yourself.\n\n\n\nThe underlying data is served in a Javascript container on the website rather than vanilla HTML. This makes it a little bit more difficult to scrape with a package like `rvest`, for example. Hence the Excel spreadsheet.\n\n\n\nTo begin the analysis, we'll read in the Excel file using the `readxl` package, and the `here` package that helps us with file paths.^[The `here` package allows us to abstract from the specific file path on our local computer and use a generic path that will work on any computer that we download our R project to. For example, instead of specifying the path \"C:/Users/Jonathan/Documents/R-work/jjayes_distill/posts/2022-01-17-flavours-of-cocoa/data/chocolate-bar-ratings.xlsx\" we can just call the `here` function from the package with the same name - here(\"posts\", \"2022-01-17-flavours-of-cocoa\", \"data\", \"chocolate-bar-ratings.xlsx\"). This is wonderful for switching between, for example, a Windows and a Mac, where the slashes are in opposite directions and can cause some frustration!]\n\nWe don't need to load the packages via the `library(readxl)` command because we're only going to use them once or twice. Instead we can call the name of the package followed by two colons and the command, as shown below.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ntheme_set(theme_light())\n# read in the data\ndf <- readxl::read_excel(here::here(\"posts\", \n                                    \"2022-01-17-flavours-of-cocoa\", \n                                    \"data\", \n                                    \"chocolate-bar-ratings.xlsx\"))\n\n# display the first six rows of tibble\nhead(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 10\n    REF Company…¹ Compa…² Revie…³ Count…⁴ Speci…⁵ Cocoa…⁶ Ingre…⁷ Most …⁸ Rating\n  <dbl> <chr>     <chr>     <dbl> <chr>   <chr>     <dbl> <chr>   <chr>    <dbl>\n1  2454 5150      U.S.A.     2019 Tanzan… Kokoa …    0.76 3- B,S… rich c…   3.25\n2  2458 5150      U.S.A.     2019 Domini… Zorzal…    0.76 3- B,S… cocoa,…   3.5 \n3  2454 5150      U.S.A.     2019 Madaga… Bejofo…    0.76 3- B,S… cocoa,…   3.75\n4  2542 5150      U.S.A.     2021 Fiji    Matasa…    0.68 3- B,S… chewy,…   3   \n5  2546 5150      U.S.A.     2021 Venezu… Sur de…    0.72 3- B,S… fatty,…   3   \n6  2546 5150      U.S.A.     2021 Uganda  Semuli…    0.8  3- B,S… mildly…   3.25\n# … with abbreviated variable names ¹​`Company (Manufacturer)`,\n#   ²​`Company Location`, ³​`Review Date`, ⁴​`Country of Bean Origin`,\n#   ⁵​`Specific Bean Origin or Bar Name`, ⁶​`Cocoa Percent`, ⁷​Ingredients,\n#   ⁸​`Most Memorable Characteristics`\n```\n:::\n:::\n\n\nThis gives us a `tibble` (similar to a dataframe) with 10 columns (4 numeric and 6 character) and 2,530 individual reviews. \n\nThe column names are a big ugly though:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# show column names\ndf %>% colnames()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"REF\"                              \"Company (Manufacturer)\"          \n [3] \"Company Location\"                 \"Review Date\"                     \n [5] \"Country of Bean Origin\"           \"Specific Bean Origin or Bar Name\"\n [7] \"Cocoa Percent\"                    \"Ingredients\"                     \n [9] \"Most Memorable Characteristics\"   \"Rating\"                          \n```\n:::\n:::\n\n\nWe can use the janitor package to make the column names snake case (lower case with words separated by an underscore).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# clean names\ndf <- df %>% \n    janitor::clean_names()\n\n# show names again\ndf %>% colnames()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"ref\"                              \"company_manufacturer\"            \n [3] \"company_location\"                 \"review_date\"                     \n [5] \"country_of_bean_origin\"           \"specific_bean_origin_or_bar_name\"\n [7] \"cocoa_percent\"                    \"ingredients\"                     \n [9] \"most_memorable_characteristics\"   \"rating\"                          \n```\n:::\n:::\n\n\nNow that we have a nice `tibble` with clean names, we can ask what the data itself looks like. There are many ways to get summary statistics of a dataset. I love the `skim` function from the `skimr` package.\n\n\n::: {.cell .column-page}\n\n```{.r .cell-code}\n# skim the dataset\nskimr::skim(df)\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |df   |\n|Number of rows           |2530 |\n|Number of columns        |10   |\n|_______________________  |     |\n|Column type frequency:   |     |\n|character                |6    |\n|numeric                  |4    |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: character**\n\n|skim_variable                    | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:--------------------------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|company_manufacturer             |         0|          1.00|   2|  39|     0|      580|          0|\n|company_location                 |         0|          1.00|   4|  21|     0|       67|          0|\n|country_of_bean_origin           |         0|          1.00|   4|  21|     0|       62|          0|\n|specific_bean_origin_or_bar_name |         0|          1.00|   3|  51|     0|     1605|          0|\n|ingredients                      |        87|          0.97|   4|  14|     0|       21|          0|\n|most_memorable_characteristics   |         0|          1.00|   3|  37|     0|     2487|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|    mean|     sd|      p0|    p25|     p50|     p75| p100|hist  |\n|:-------------|---------:|-------------:|-------:|------:|-------:|------:|-------:|-------:|----:|:-----|\n|ref           |         0|             1| 1429.80| 757.65|    5.00|  802.0| 1454.00| 2079.00| 2712|▆▇▇▇▇ |\n|review_date   |         0|             1| 2014.37|   3.97| 2006.00| 2012.0| 2015.00| 2018.00| 2021|▃▅▇▆▅ |\n|cocoa_percent |         0|             1|    0.72|   0.06|    0.42|    0.7|    0.70|    0.74|    1|▁▁▇▁▁ |\n|rating        |         0|             1|    3.20|   0.45|    1.00|    3.0|    3.25|    3.50|    4|▁▁▅▇▇ |\n:::\n:::\n\n\nGreat! Our reviews are almost all complete. \n\n*   Only 3 percent are missing information on the ingredients. \n*   The reviews begin in 2006, the mean review is from 2014, and the latest is from 2021. \n*   The percent of the bar comprising of cocoa ranges from 42 to 100, with a mean of 72.\n*   We have 62 unique countries of origin for the beans, and 67 countries of manufacture.\n*   There are 21 unique combinations of ingredients, comprising of seven elements in total.\n\n## Data cleaning and feature engineering\n\nLet's have a look at that ingredients column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# count elements of ingredients column\ndf %>% \n    count(ingredients, sort = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 22 × 2\n   ingredients      n\n   <chr>        <int>\n 1 3- B,S,C       999\n 2 2- B,S         718\n 3 4- B,S,C,L     286\n 4 5- B,S,C,V,L   184\n 5 4- B,S,C,V     141\n 6 <NA>            87\n 7 2- B,S*         31\n 8 4- B,S*,C,Sa    20\n 9 3- B,S*,C       12\n10 3- B,S,L         8\n# … with 12 more rows\n```\n:::\n:::\n\n\nSo we have a number of ingredients, a dash, and then a key for what the ingredients are. Consulting the website reveals that there are seven possible ingredients:\n\n\n::: {.cell}\n::: {.cell-output-display}\n|key |value                                         |\n|:---|:---------------------------------------------|\n|B   |Beans                                         |\n|S   |Sugar                                         |\n|S*  |Sweetener other than white cane or beet sugar |\n|C   |Cocoa Butter                                  |\n|V   |Vanilla                                       |\n|L   |Lecithin                                      |\n|Sa  |Salt                                          |\n:::\n:::\n\n\nThese key and value combinations are very sensible - if we have a lot of data we can save space by using the keys instead of the whole string. However, I would prefer to have them written out, because we're going to split them into their own columns a little bit later. \n\nWe can use the `str_replace_all` function from the `stringr` package to replace items in the list of ingredients with names.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- df %>% \n  mutate(ingredients = str_replace_all(ingredients, c(\"Sa\" = \"salt\",\n                                                      # the * is a special character \n                                                      # when writing Regex and so \n                                                      # we use the two backslashes to \n                                                      # \"escape\" the meaning\n                                                      \"S\\\\*\" = \"non_sugar_sweetener\",\n                                                      \"B\" = \"beans\",\n                                                      \"S\" =  \"sugar\",\n                                                      \"V\" = \"vanilla\",\n                                                      \"L\" = \"lecithin\",\n                                                      \"C\" = \"cocoa_butter\"\n                                                      )))\n```\n:::\n\n\nLet's look again at our ingredients column:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf %>% \n    count(ingredients, sort = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 22 × 2\n   ingredients                                        n\n   <chr>                                          <int>\n 1 3- beans,sugar,cocoa_butter                      999\n 2 2- beans,sugar                                   718\n 3 4- beans,sugar,cocoa_butter,lecithin             286\n 4 5- beans,sugar,cocoa_butter,vanilla,lecithin     184\n 5 4- beans,sugar,cocoa_butter,vanilla              141\n 6 <NA>                                              87\n 7 2- beans,non_sugar_sweetener                      31\n 8 4- beans,non_sugar_sweetener,cocoa_butter,salt    20\n 9 3- beans,non_sugar_sweetener,cocoa_butter         12\n10 3- beans,sugar,lecithin                            8\n# … with 12 more rows\n```\n:::\n:::\n\n\nFantastic! Now we have the number of ingredients, a dash, and then each ingredient by name in one column. Let's separate this information into two columns so that we can use the number of ingredients as a feature.\n\nThe `separate` function from the `tidyr` package is made just for this purpose. It takes three arguments:\n\n1. the name of the column to separate.\n2. new column names corresponding to the number of elements.\n3. the separator between elements.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- df %>% \n  separate(col = ingredients, \n           into = c(\"n_ingredients\", \"ingredients\"),\n           sep = \"-\") %>% \n    # parse_number looks for a number inside a character column and discards the rest\n  mutate(n_ingredients = parse_number(n_ingredients),\n         # str_squish removes whitespace around the elements in the ingredients column\n         ingredients = str_squish(ingredients))\n\ndf %>% \n  select(n_ingredients, ingredients)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,530 × 2\n   n_ingredients ingredients                      \n           <dbl> <chr>                            \n 1             3 beans,sugar,cocoa_butter         \n 2             3 beans,sugar,cocoa_butter         \n 3             3 beans,sugar,cocoa_butter         \n 4             3 beans,sugar,cocoa_butter         \n 5             3 beans,sugar,cocoa_butter         \n 6             3 beans,sugar,cocoa_butter         \n 7             3 beans,sugar,cocoa_butter         \n 8             4 beans,sugar,cocoa_butter,lecithin\n 9             4 beans,sugar,cocoa_butter,lecithin\n10             4 beans,sugar,cocoa_butter,lecithin\n# … with 2,520 more rows\n```\n:::\n:::\n\n\nNow we have a numeric column with the number of ingredints and a column called ingredients with each element separated by a comma.\n\nFinally, let's break the ingredients from a comma separated list into a binary variable for each ingredient. We can use the `recipes` package that is part of the `tidymodels` metapackage - a framework for doing statistical modelling in a tidy manner.\n\nFirst we break our ingredients into 6 columns. The problem we run into is that for bars that contain different ingredients, the order of the ingredients split into the columns is not constant.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# df <- df %>% \n#   separate(ingredients, into = c(paste0(\"ingredient_\", rep(1:6))),\n#            sep = \",\") \n\n# df %>% \n#     select(company_manufacturer , starts_with(\"ingredient_\")) %>%\n#     slice(c(1L, 51L, 54L))\n```\n:::\n\n\nPerhaps there is a better way to do this? Separate rows and pivot wider?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf %>% \n    separate_rows(ingredients, sep = \",\") %>%\n    count(ingredients)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 2\n  ingredients             n\n  <chr>               <int>\n1 beans                2443\n2 cocoa_butter         1668\n3 lecithin              493\n4 non_sugar_sweetener    76\n5 salt                   37\n6 sugar                2360\n7 vanilla               353\n8 <NA>                   87\n```\n:::\n\n```{.r .cell-code}\ndf <- df %>% \n    separate_rows(ingredients, sep = \",\") %>%\n    filter(!is.na(ingredients)) %>% \n    pivot_wider(names_from = ingredients, values_from = ingredients) %>% \n    mutate(across(beans:non_sugar_sweetener, ~ ifelse(is.na(.), 0, 1)))\n```\n:::\n\n\n\n\nTidymodels \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(tidymodels)\n# dummy_multi_choice_rec <- recipe(~ ., data = df) %>%\n#   step_dummy_multi_choice(starts_with(\"ingredient_\")) %>%\n#   prep()\n# \n# df <- bake(dummy_multi_choice_rec, new_data = NULL)\n```\n:::\n\n\n## Analysing the data\n\n### Basic descriptives\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf %>% \n  count(rating, sort = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 × 2\n   rating     n\n    <dbl> <int>\n 1   3.5    552\n 2   3      506\n 3   3.25   453\n 4   2.75   320\n 5   3.75   295\n 6   2.5    156\n 7   4      111\n 8   2       29\n 9   2.25    14\n10   1.5      5\n11   1        1\n12   1.75     1\n```\n:::\n:::\n\n\nScore range between 1 and 4, and the modal value is 3.5.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# histogram\ndf %>% \n  ggplot(aes(rating)) +\n  geom_histogram(bins = 14, alpha = .7, fill = \"midnightblue\") +\n    labs(x = \"Chocolate bar rating\",\n         y = \"Number of bars\")\n```\n\n::: {.cell-output-display}\n![](flavours-of-cocoa_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n### Have the ratings been increasing over time?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf %>% \n    group_by(review_date) %>% \n    summarise(mean_rating = mean(rating)) %>% \n    ungroup() %>% \n    knitr::kable(digits = 2)\n```\n\n::: {.cell-output-display}\n| review_date| mean_rating|\n|-----------:|-----------:|\n|        2006|        3.06|\n|        2007|        3.17|\n|        2008|        3.04|\n|        2009|        3.09|\n|        2010|        3.19|\n|        2011|        3.27|\n|        2012|        3.21|\n|        2013|        3.21|\n|        2014|        3.20|\n|        2015|        3.24|\n|        2016|        3.24|\n|        2017|        3.36|\n|        2018|        3.19|\n|        2019|        3.13|\n|        2020|        3.26|\n|        2021|        3.32|\n:::\n:::\n\n\nIt certainly seems like the mean rating is increasing over time. What is driving this?\n\n\n\nWe can make a plot of the figures above to see the increasing trend.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf %>% \n    group_by(review_date) %>% \n    summarise(mean_rating = mean(rating)) %>% \n    ungroup() %>% \n    ggplot(aes(review_date, mean_rating)) +\n    geom_point(colour = \"midnightblue\", alpha = .6, size = 5) +\n    geom_smooth(method = \"lm\", se = F, colour = \"grey20\") +\n    labs(x = \"Date of review\",\n         y = \"Mean rating\")\n```\n\n::: {.cell-output-display}\n![](flavours-of-cocoa_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n\nLet's make a boxplot to see how the spread of scores has changed over time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf %>%\n  ggplot(aes(review_date, rating, group = review_date)) +\n  geom_jitter(alpha = .2) +\n  geom_boxplot(varwidth = TRUE, fill = \"midnightblue\", alpha = .6)\n```\n\n::: {.cell-output-display}\n![](flavours-of-cocoa_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nIt seems as if the share of bars with very low scores has decreased over time, while the median value has remained relatively stable over time, shown by the bar in the centre of the boxplots.\n\nWhat about making a joy plot or ridgeline plot with the `ggridges` package? This allows us to see how the spread of values has changed over time.\n\n\n::: {.cell .column-page}\n\n```{.r .cell-code}\nlibrary(ggridges)\n\ndf %>%\n  ggplot(aes(rating, y = factor(review_date), fill = review_date)) +\n  geom_density_ridges() +\n  scale_fill_viridis_c(option = \"magma\") +\n  theme(legend.position = \"bottom\") +\n  guides(fill = guide_colorbar(\n    title.position = \"bottom\",\n    barwidth = 25,\n    title.hjust = .5\n  )) +\n    labs(y = NULL,\n         x = \"Chocolate bar rating\",\n         fill = \"Date of review\")\n```\n\n::: {.cell-output-display}\n![](flavours-of-cocoa_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nThis confirms what we saw in the boxplots above: fewer low scores in more recent years mean that the mean has increased, while the top of the distributions remain largely the same.\n\n### What are the frequencies of ingredients and percentages?\n\n\n::: {.cell .column-page}\n\n```{.r .cell-code}\ndf %>% \n  mutate(cocoa_percent = round(cocoa_percent, 1)) %>% \n  count(cocoa_percent, n_ingredients) %>% \n  ggplot(aes(cocoa_percent, n_ingredients, fill = n)) +\n  geom_tile() +\n  scale_fill_viridis_c() +\n  scale_x_continuous(labels = scales::percent_format()) +\n  labs(x = \"Cocoa percent\",\n       y = \"Number of ingredients\",\n       fill = \"Number of bars reviewed\") +\n  theme(legend.position = \"bottom\") +\n  guides(fill = guide_colorbar(title.position = \"bottom\",\n                               barwidth = 25,\n                               title.hjust = .5))\n```\n\n::: {.cell-output-display}\n![](flavours-of-cocoa_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\n### What about the different countries??\n\n\n::: {.cell .column-page}\n\n```{.r .cell-code}\ndf %>% \n  count(country_of_bean_origin, sort = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 62 × 2\n   country_of_bean_origin     n\n   <chr>                  <int>\n 1 Venezuela                246\n 2 Peru                     231\n 3 Dominican Republic       220\n 4 Ecuador                  201\n 5 Madagascar               171\n 6 Blend                    144\n 7 Nicaragua                100\n 8 Bolivia                   79\n 9 Colombia                  78\n10 Tanzania                  78\n# … with 52 more rows\n```\n:::\n\n```{.r .cell-code}\ndf %>% \n  add_count(country_of_bean_origin) %>%\n  # only include countries with more than 60 bars\n  filter(n > 60) %>% \n  group_by(country_of_bean_origin) %>% \n  summarise(mean_rating = mean(rating)) %>% \n  mutate(country_of_bean_origin = fct_reorder(country_of_bean_origin, mean_rating)) %>% \n  ggplot(aes(mean_rating, country_of_bean_origin)) +\n  geom_col(fill = \"midnightblue\", alpha = .8) +\n  # ensure that x-axis looks appropriate.\n  coord_cartesian(xlim = c(3,3.3)) +\n    labs(x = \"Average rating for countries of origin with more than 60 bars reviewed\",\n         y = NULL)\n```\n\n::: {.cell-output-display}\n![](flavours-of-cocoa_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n### Country map\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tmap)\ndata(\"World\")\n\nworld <- World %>% as_tibble()\n```\n:::\n\n\nTo join our data on chocolate to this map, we need to get coutnry codes, using the `countrycode` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(countrycode)\n\ndf <- df %>% \n    mutate(iso_a3 = countrycode(sourcevar = country_of_bean_origin, origin = \"country.name\", destination = \"iso3c\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\n\ndf_map <- df %>% \n    group_by(iso_a3) %>%\n    add_count() %>% \n    summarise(mean_rating = mean(rating),\n              n = n) %>% \n    ungroup() %>% \n    distinct() %>% \n    left_join(world, by = \"iso_a3\")\n```\n:::\n\n::: {.cell .column-page}\n\n```{.r .cell-code}\ndf_map %>% \n    filter(n > 3) %>% \n    st_as_sf() %>% ggplot() +\n    geom_sf(data = World, fill = \"grey80\", alpha = .5) +\n    geom_sf(aes(fill = mean_rating)) +\n    scale_fill_viridis_c(trans = \"sqrt\") +\n    labs(fill = \"Mean country rating\")\n```\n\n::: {.cell-output-display}\n![](flavours-of-cocoa_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n## Word model\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_characteristics <- df %>% \n  select(c(most_memorable_characteristics, rating)) %>% \n  separate_rows(most_memorable_characteristics, sep = \",\") %>% \n  mutate(most_memorable_characteristics = str_squish(most_memorable_characteristics))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_characteristics %>% \n  count(most_memorable_characteristics, sort = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 948 × 2\n   most_memorable_characteristics     n\n   <chr>                          <int>\n 1 sweet                            260\n 2 nutty                            256\n 3 cocoa                            242\n 4 roasty                           212\n 5 creamy                           187\n 6 earthy                           181\n 7 sandy                            164\n 8 fatty                            161\n 9 floral                           141\n10 intense                          139\n# … with 938 more rows\n```\n:::\n:::\n\n\nWe can start with a naive analysis that looks only at average score per word. These are the highest scoring words.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# df_characteristics %>% \n#   group_by(most_memorable_characteristics) %>% \n#   add_count() %>% \n#   mutate(avg_rating = mean(rating)) %>% \n#   ungroup() %>% \n#   slice_max(avg_rating, n = 12, with_ties = F)\n\ndf_characteristics %>% \n  group_by(most_memorable_characteristics) %>% \n  add_count() %>% \n  filter(n > 3) %>% \n  mutate(avg_rating = mean(rating)) %>% \n  ungroup() %>% \n  distinct(most_memorable_characteristics, avg_rating) %>% \n  slice_max(avg_rating, n = 12, with_ties = F) %>% \n    mutate(avg_rating = round(avg_rating, 2)) %>% \n    knitr::kable(col.names = c(\"Most memorable characteristics\", \"Average rating\"))\n```\n\n::: {.cell-output-display}\n|Most memorable characteristics | Average rating|\n|:------------------------------|--------------:|\n|peanut                         |           3.75|\n|wine                           |           3.75|\n|balanced                       |           3.73|\n|raspberry                      |           3.70|\n|mild tart                      |           3.69|\n|robust                         |           3.69|\n|rich choco                     |           3.69|\n|long lasting                   |           3.62|\n|blackberry                     |           3.61|\n|dark berry                     |           3.61|\n|subtle                         |           3.61|\n|delicate                       |           3.60|\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(textrecipes)\n\ndf_characteristics_folds <- vfold_cv(df_characteristics)\n\nglmnet_recipe <- \n  recipe(formula = rating ~ ., data = df_characteristics) %>% \n  step_tokenize(most_memorable_characteristics) %>% \n  step_tokenfilter(most_memorable_characteristics, max_tokens = 100) %>% \n  step_tf(most_memorable_characteristics) %>% \n  step_normalize(all_predictors(), -all_nominal())\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglmnet_recipe %>% prep() %>% juice()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6,839 × 101\n   rating tf_most_memo…¹ tf_mo…² tf_mo…³ tf_mo…⁴ tf_mo…⁵ tf_mo…⁶ tf_mo…⁷ tf_mo…⁸\n    <dbl>          <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1   3.25        -0.0767 -0.0630 -0.0805 -0.0528 -0.0949 -0.0528 -0.0696  -0.107\n 2   3.25        -0.0767 -0.0630 -0.0805 -0.0528 -0.0949 -0.0528 -0.0696  -0.107\n 3   3.25        -0.0767 -0.0630 -0.0805 -0.0528 -0.0949 -0.0528 -0.0696  -0.107\n 4   3.5         -0.0767 -0.0630 -0.0805 -0.0528 -0.0949 -0.0528 -0.0696  -0.107\n 5   3.5         -0.0767 -0.0630 -0.0805 -0.0528 -0.0949 -0.0528 -0.0696  -0.107\n 6   3.5         -0.0767 -0.0630 -0.0805 -0.0528 -0.0949 -0.0528 -0.0696  -0.107\n 7   3.75        -0.0767 -0.0630 -0.0805 -0.0528 -0.0949 -0.0528 -0.0696  -0.107\n 8   3.75        -0.0767 -0.0630 -0.0805 -0.0528 -0.0949 -0.0528 -0.0696  -0.107\n 9   3.75        -0.0767 -0.0630 -0.0805 -0.0528 -0.0949 -0.0528 -0.0696  -0.107\n10   3           -0.0767 -0.0630 -0.0805 -0.0528 -0.0949 -0.0528 -0.0696  -0.107\n# … with 6,829 more rows, 92 more variables:\n#   tf_most_memorable_characteristics_bitter <dbl>,\n#   tf_most_memorable_characteristics_black <dbl>,\n#   tf_most_memorable_characteristics_bland <dbl>,\n#   tf_most_memorable_characteristics_bold <dbl>,\n#   tf_most_memorable_characteristics_bright <dbl>,\n#   tf_most_memorable_characteristics_brownie <dbl>, …\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglmnet_spec <- \n  linear_reg(penalty = tune(), mixture = 1) %>% \n  set_mode(\"regression\") %>% \n  set_engine(\"glmnet\") \n\nglmnet_workflow <- \n  workflow() %>% \n  add_recipe(glmnet_recipe) %>% \n  add_model(glmnet_spec) \n\nglmnet_grid <- tidyr::crossing(penalty = 10^seq(-6, -1, length.out = 20)) \n\nglmnet_tune <- \n  tune_grid(glmnet_workflow, df_characteristics_folds, grid = glmnet_grid)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglmnet_tune %>% \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](flavours-of-cocoa_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglmnet_model_final <- finalize_workflow(glmnet_workflow, glmnet_tune %>% \n  select_best())\n\nfinal_fit <- glmnet_model_final %>% \n  fit(df_characteristics)\n```\n:::\n\n\nWhat does the fit look like? These are the terms that have the greatest effect on bar rating.\n\n\n\n\n::: {.cell .column-page}\n\n```{.r .cell-code}\nfinal_fit %>%\n  extract_fit_parsnip() %>%\n  tidy() %>%\n  filter(term != \"(Intercept)\") %>%\n  mutate(term = str_remove(term, \"tf_most_memorable_characteristics_\")) %>%\n  mutate(sign = estimate > 0) %>%\n  group_by(sign) %>%\n  mutate(estimate = abs(estimate)) %>% \n  slice_max(estimate, n = 12) %>%\n  ungroup() %>%\n  mutate(estimate = ifelse(sign == TRUE, estimate, -estimate)) %>% \n  mutate(term = fct_reorder(term, estimate)) %>%\n  ggplot(aes(estimate, term, fill = sign)) +\n  geom_col(show.legend = F) +\n  geom_vline(xintercept = 0, lty = 2) +\n  scale_fill_brewer(palette = \"Paired\") +\n  labs(x = \"Effect of term on chocolate bar score\",\n       y = \"Memorable characteristic\")\n```\n\n::: {.cell-output-display}\n![](flavours-of-cocoa_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\n\nWow! have a look at the terms up top - \"creamy\", \"complex\" and \"rich\" are good chocolate words. On the other side, \"bitter\", \"off\" and \"chemical\" are terms that lower the score of the bar.\n\n",
    "supporting": [
      "flavours-of-cocoa_files\\figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}